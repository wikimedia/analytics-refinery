#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Note: You should make sure to put refinery/python on your PYTHONPATH.
#   export PYTHONPATH=$PYTHONPATH:/path/to/refinery/python
"""
This script deletes old snapshots from the druid cluster. It is useful to
keep a few recent snapshots in case the most recent data turns out to be
defective and a revert is necessary, but there should be no need to
keep all snapshots.

DO NOT use this script on druid datasources whose intervals represent time
data other than snapshots. For example, geowiki_archive_monthly's intervals
represent the time ranges of the data, which we wouldn't want to delete.

Usage: refinery-drop-druid-snapshots [options]

Options:
    -h --help                        Show this help message and exit.
    -d --basename=<name>             Base name of the datasource from which data will
                                     be deleted. Assumes that the datasources name will be
                                     <BASE_NAME>_yyyy_MM
    -t --druid-host=<host>           Druid's hostname (can be any node of the cluster)
    -c --druid-coord-port=<port>     Port for druid coordinator [default: 8081]
    -o --druid-overlord-port=<port>  Port for druid overlord [default: 8090]
    -s --keep-snapshots=<n>          Keep the <n> most recent snapshots. [default: 6]
    -v --verbose                     Turn on verbose debug logging.
    -f --log-file=<file>             File to send info logs to
    -w --wait-between-checks=<s>     Sleeping time in second between task status updates.
                                     [default: 5]
    -n --dry-run                     Don't actually drop any partitions, just output Hive queries.
"""

__author__ = 'Francisco Dans <fdans@wikimedia.org>'

import re
import sys
from docopt import docopt
import logging
from refinery.druid import Druid
from refinery.logging_setup import configure_logging

logger = logging.getLogger()

if __name__ == '__main__':
    arguments = docopt(__doc__)

    keep                = int(arguments['--keep-snapshots'])
    basename            = arguments['--basename']
    druid_host          = arguments['--druid-host']
    druid_coord_port    = arguments['--druid-coord-port']
    druid_overlord_port = arguments['--druid-overlord-port']
    wait_seconds        = int(arguments['--wait-between-checks'])
    verbose             = arguments['--verbose']
    dry_run             = arguments['--dry-run']
    log_file            = arguments['--log-file']

    log_level = logging.DEBUG if verbose else logging.INFO
    configure_logging(logger, log_level, log_file=log_file)

    if dry_run:
        print('################################################')
        print('DRY RUN MODE - THIS RUN WILL NOT CHANGE ANYTHING')
        print('################################################')

    druid = Druid(druid_host, druid_coord_port, druid_overlord_port)

    logger.info('Looking for snapshots to delete for basename {}'.format(basename))
    datasources = druid.list_datasources()
    matched_datasources = filter(lambda d: re.match(basename + '_\d{4}_\d\d', d),datasources)
    ordered_matched_datasources = list(sorted(matched_datasources, reverse = True))
    if len(ordered_matched_datasources) == 0:
        sys.exit('No datasource match basename {}'.format(basename))
    datasources_to_remove = ordered_matched_datasources[keep:]
    if len(datasources_to_remove) == 0:
        logger.info('No datasource to remove ({} available: {})'.format(
                    len(ordered_matched_datasources), str(ordered_matched_datasources)))
        sys.exit(0)
    for datasource in datasources_to_remove:
        druid.delete_datasource(datasource, wait_seconds   , dry_run)

    logger.info('Deleted {} datasources: {}'.format(
        len(datasources_to_remove), datasources_to_remove))
