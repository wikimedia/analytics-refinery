#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Note: You should make sure to put refinery/python on your PYTHONPATH.
#   export PYTHONPATH=$PYTHONPATH:/path/to/refinery/python

"""
Prints out the ALTER TABLE webrequest ADD PARTITION ... statements that would need
to be run to in order to recreate all of the partitions that currently exist for
a webrequest table.  This is useful in case you need to recreate an external webrequest
table from scratch, and want to re-add the existant partitions to this new table.

Usage: refinery-add-webrequest-partition-statements [options]

Options:
    -h --help                           Show this help message and exit.
    -D --database=<dbname>              Hive database name.  [default: default]
    -t --table=<table>                  Name of webrequest table.  [default: webrequest]
    -l --location=<location>            Base HDFS location path of the webrequest table.  If not
                                        specified, this will be inferred from the table schema metadata.
    -w --webrequest-type=<type>         Either 'raw' or 'refined'.  [default: raw]
    -v --verbose                        Turn on verbose debug logging.

TODO: Abstract useful webrequest functions into a library.
"""
__author__ = 'Andrew Otto <otto@wikimedia.org>'

from   docopt   import docopt
import re
import os
import logging

from refinery.hive import Hive
from refinery.hdfs import Hdfs

# Allows easy extraction of partition fields from the partition spec.
# This regex is used with Hive partition_datetime_from_spec.
# and could be used with HDFS partition paths that match the default
# Hive partition layout (I.e. key1=val1/key2=val2, etc.)
partition_spec_regex   = re.compile(r'webrequest_source=(?P<webrequest_source>[^/,]+)[/,]year=(?P<year>[^/,]+)[/,]month=(?P<month>[^/,]+)[/,]day=(?P<day>[^/]+)[/,]hour=(?P<hour>[^/,]+)')


def webrequest_raw_partition_path_from_spec(location, spec):
    """
    Given a raw webrequest table location and a webrequest partition spec,
    this will return full partition path to the partition the spec describes.
    """
    matches = partition_spec_regex.match(spec)
    return os.path.join(
        location,
        'webrequest_' + matches.group('webrequest_source').replace("'", ''),
        'hourly',
        matches.group('year').zfill(2),
        matches.group('month').zfill(2),
        matches.group('day').zfill(2),
        matches.group('hour').zfill(2),
    )


def webrequest_refined_partition_path_from_spec(location, spec):
    """
    Given a refined webrequest table location and a webrequest partition spec,
    this will return full partition path to the partition the spec describes.
    """
    matches = partition_spec_regex.match(spec)
    return os.path.join(
        location,
        "webrequest_source={0}".format(matches.group('webrequest_source').replace("'", '')),
        'year='     + matches.group('year'),
        'month='    + matches.group('month'),
        'day='      + matches.group('day'),
        'hour='     + matches.group('hour'),
    )


def webrequest_add_partition_statements(database='wmf_raw', table='webrequest', location=None, webrequest_type='raw'):
    """
    Given an existant webrequest table with partitions already added, this will return
    a List of ADD PARTITION statements that could be used to re-add all of the partitions.
    """


    if webrequest_type == 'raw':
        hive_options = '--auxpath /usr/lib/hive-hcatalog/share/hcatalog/hive-hcatalog-core.jar'
    else:
        hive_options = ''

    hive = Hive(database, options=hive_options)

    # The base location of this webrequest table in HDFS.
    # If it was not provided via the CLI, then attempt to
    # infer if from the table metadata.
    if location == None:
        location = hive.table_location(table)

    if not Hdfs.validate_path(location):
        logging.error('{0} table location \'{1}\' is not a valid HDFS path.  Path must start with \'/\' or \'hdfs://\'.  Aborting.'
            .format(table, location))
        sys.exit(1)

    statements = []
    for spec in hive.partition_specs(table):
        if webrequest_type == 'raw':
            path = webrequest_raw_partition_path_from_spec(location, spec)
        else:
            path = webrequest_refined_partition_path_from_spec(location, spec)

        statements.append('ALTER TABLE {0} ADD PARTITION ({1}) LOCATION "{2}";'.format(
            table,
            spec,
            path
        ))
    return statements

if __name__ == '__main__':
    # parse arguments
    arguments = docopt(__doc__)
    database        = arguments['--database']
    table           = arguments['--table']
    table_location  = arguments['--location']
    webrequest_type = arguments['--webrequest-type']
    verbose         = arguments['--verbose']

    log_level = logging.INFO
    if verbose:
        log_level = logging.DEBUG

    logging.basicConfig(level=log_level,
                        format='%(asctime)s %(levelname)-6s %(message)s',
                        datefmt='%Y-%m-%dT%H:%M:%S')

    if webrequest_type not in ['raw', 'refined']:
        logging.error('\'{0}\' is not a valid webrequest-type.  Must be one of \'raw\' or \'refined\''
             .format(webrequest_type))
        sys.exit(1)

    add_partition_statements = webrequest_add_partition_statements(database, table, table_location, webrequest_type)
    for p in add_partition_statements:
        print(p)

