--Generate ArticlePlaceholder extension metrics for Wikidata
--
--The hql script is used as input to a HiveToGraphite spark job
--https://gerrit.wikimedia.org/r/plugins/gitiles/analytics/refinery/source/+/refs/heads/master/refinery-job/src/main/scala/org/wikimedia/analytics/refinery/job/HiveToGraphite.scala
--The HiveToGraphite job will be used with this script to replace the WikidataArticlePlaceholderMetrics.scala job
--https://gerrit.wikimedia.org/r/plugins/gitiles/analytics/refinery/source/+/refs/heads/master/refinery-job/src/main/scala/org/wikimedia/analytics/refinery/job/wikidata/WikidataArticlePlaceholderMetrics.scala
--
--The metrics for Wikidata's ArticlePlaceholder extension are purely generated by this script.
--The metric would be sent to Graphite by the HiveToGraphite job.
--
-- Parameters:
--     webrequest_table   -- The webrequest table to query.
--     year               -- year of metric to compute for .
--     month              -- month of metric to compute for .
--     day                -- day of metric to compute for .
--     coalesce_partitions-- the number of partitions.
--
-- Usage:
--     spark3-sql --master yarn -f wikidata_articleplaceholder_metrics.hql    \
--         -d webrequest_table=wmf.webrequest                                 \
--         -d year=2021                                                       \
--         -d month=5                                                         \
--         -d day=4                                                           \
--         -d coalesce_partitions=4                                           \
--

CREATE TEMPORARY VIEW wd_articleplaceholder_data AS
SELECT
  CONCAT(normalized_host.project, '_', normalized_host.project_family) AS project,
  agent_type,
  (referer rlike '^.*search=.*$$' AND referer rlike '^.*\\.wikipedia\\.org.*$$') as from_search,
  COUNT(1) as count,
  CAST('${year}-${month}-${day}' as timestamp ) as ts
FROM ${webrequest_table}
WHERE webrequest_source = 'text'
  AND year = ${year}
  AND month = ${month}
  AND day = ${day}
  AND x_analytics_map["ns"] = '-1'
  AND x_analytics_map["special"] = 'AboutTopic'
  AND normalized_host.project_family = 'wikipedia'
GROUP BY
  CONCAT(normalized_host.project, '_', normalized_host.project_family),
  agent_type,
  (referer rlike '^.*search=.*$$' AND referer rlike '^.*\\.wikipedia\\.org.*$$');

CACHE TABLE wd_articleplaceholder_data;

WITH
agent_project AS (
  SELECT /*+ COALESCE(${coalesce_partitions}) */
    CONCAT(agent_type,'.',project) as metric_id,
    SUM(count) as metric_count,
    ts
  FROM wd_articleplaceholder_data
  GROUP BY
    CONCAT(agent_type,'.',project),
    ts
),

fromsearch_true AS (
  SELECT /*+ COALESCE(${coalesce_partitions}) */
    CONCAT('search_referral.',project) as metric_id,
    SUM(count) as metric_count,
    ts
  FROM wd_articleplaceholder_data
  WHERE from_search='True'
  GROUP BY
    CONCAT('search_referral.',project),
    ts
)

SELECT * FROM agent_project
UNION
SELECT * FROM fromsearch_true;
