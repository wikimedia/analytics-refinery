--Generates Reliability metrics for wikidata
--
--Metrics includes median page weight, median loading time and edge cache hit ratio.
--
--The hql script is used as input to a HiveToGraphite spark job
--https://gerrit.wikimedia.org/r/plugins/gitiles/analytics/refinery/source/+/refs/heads/master/refinery-job/src/main/scala/org/wikimedia/analytics/refinery/job/HiveToGraphite.scala
--The HiveToGraphite job will be used with this script to replace the WikidataReliabilityMetrics.scala job
--https://gerrit.wikimedia.org/r/plugins/gitiles/analytics/refinery/source/+/refs/heads/master/refinery-job/src/main/scala/org/wikimedia/analytics/refinery/job/wikidata/WikidataReliabilityMetrics.scala
--
--The metrics for Wikidata's Reliability is purely generated by this script.
--The metric would be sent to Graphite by the HiveToGraphite job.
--
--How the query works:
--      Create a sub_query wd_reliability_data that will extract all the information needed for the metrics
--        for a given day.
--      Generate the median page weight (median_payload metric) from wd_reliability_data.
--      Generate the median loading time (median_time_query) from wd_reliability_data.
--      Generate the edge cache hit(request_count_query) from wd_reliability_data.
--      Lastly combine all metrics using union.
--
-- Parameters:
--     webrequest_table   -- The webrequest table to query.
--     year               -- year of metric to compute for .
--     month              -- month of metric to compute for .
--     day                -- day of metric to compute for .
--
-- Usage:
--     spark3-sql --master yarn -f wikidata_reliability_metrics.hql    \
--         -d webrequest_table=wmf.webrequest                          \
--         -d year=2021                                                \
--         -d month=5                                                  \
--         -d day=4                                                    \
--         -d coalesce_partitions=4                                    \
--

CREATE TEMPORARY VIEW wd_reliability_data AS
  SELECT
    uri_host,
    uri_path,
    namespace_id,
    http_status,
    is_pageview,
    response_size,
    CAST(time_firstbyte * 1000 AS bigint) AS time_firstbyte,
    cache_status
  FROM ${webrequest_table}
  WHERE
    webrequest_source = 'text'
    AND year = ${year}
    AND month = ${month}
    AND day = ${day}
    AND uri_host IN ('www.wikidata.org', 'query.wikidata.org', 'm.wikidata.org')
    AND (is_pageview = TRUE OR uri_path LIKE '/w/api.php%' OR uri_path LIKE '%/sparql');

CACHE TABLE wd_reliability_data;

WITH
median_payload_query AS (
  SELECT /*+ COALESCE(${coalesce_partitions}) */
    'median_payload' AS metric_id,
    percentile_approx(response_size, 0.5) AS metric_count,
    CAST('${year}-${month}-${day}' AS timestamp ) AS ts
  FROM
    wd_reliability_data
  WHERE
    http_status = 200
    AND uri_host IN ('www.wikidata.org', 'm.wikidata.org')
    AND namespace_id IN (0,120,146)
    AND is_pageview = TRUE
),

median_time_query AS (
  SELECT /*+ COALESCE(${coalesce_partitions}) */
    'median_time' AS metric_id,
    percentile_approx(time_firstbyte, 0.5) AS metric_count,
    CAST('${year}-${month}-${day}' AS timestamp ) AS ts
  FROM
    wd_reliability_data
  WHERE
    uri_host IN ('www.wikidata.org', 'm.wikidata.org')
    AND namespace_id IN (0,120)
    AND http_status = 200
    AND is_pageview = TRUE
    AND cache_status = 'miss'
),

request_count_query AS (
  SELECT /*+ COALESCE(${coalesce_partitions}) */
    COUNT(*) AS metric_count,
    CASE WHEN is_pageview = TRUE THEN 'entity_page'
      WHEN uri_path LIKE '/w/api.php%' THEN 'api'
      WHEN uri_host = 'query.wikidata.org' AND uri_path LIKE '%/sparql' THEN 'wdqs'
      ELSE 'other'
    END AS request_category,
    CASE WHEN cache_status IN ('pass','miss') THEN 'miss' ELSE 'hit' END AS is_cached,
    CAST('${year}-${month}-${day}' AS timestamp ) AS ts
  FROM
    wd_reliability_data
  GROUP BY
    (CASE WHEN is_pageview = TRUE THEN 'entity_page'
      WHEN uri_path LIKE '/w/api.php%' THEN 'api'
      WHEN uri_host = 'query.wikidata.org' AND uri_path LIKE '%/sparql' THEN 'wdqs'
      ELSE 'other'
    END),
    (CASE WHEN cache_status IN ('pass','miss') THEN 'miss' ELSE 'hit' END)
)

SELECT *
FROM median_payload_query
UNION
SELECT *
FROM median_time_query
UNION
SELECT
  CONCAT('request_count.',request_category,'.',is_cached),
  metric_count,
  ts
FROM
request_count_query;
