<?xml version="1.0" encoding="UTF-8"?>
<coordinator-app xmlns="uri:oozie:coordinator:0.4"
    xmlns:sla="uri:oozie:sla:0.2"
    name="webrequest-load-coord-${webrequest_source}"
    frequency="${coord:hours(1)}"
    start="${start_time}"
    end="${stop_time}"
    timezone="Universal">

    <parameters>

        <!-- Required properties -->
        <property><name>queue_name</name></property>
        <property><name>name_node</name></property>
        <property><name>job_tracker</name></property>
        <property><name>hive_principal</name></property>
        <property><name>hive2_jdbc_url</name></property>
        <property><name>workflow_file</name></property>
        <property><name>start_time</name></property>
        <property><name>stop_time</name></property>
        <property><name>webrequest_raw_datasets_file</name></property>
        <property><name>webrequest_raw_data_directory</name></property>
        <property><name>webrequest_datasets_file</name></property>
        <property><name>webrequest_data_directory</name></property>

        <property><name>hive_site_xml</name></property>
        <property><name>add_partition_workflow_file</name></property>
        <property><name>refinery_jar_version</name></property>
        <property><name>artifacts_directory</name></property>
        <property><name>webrequest_raw_table</name></property>
        <property><name>webrequest_table</name></property>
        <property><name>statistics_table</name></property>
        <property><name>statistics_hourly_table</name></property>
        <property><name>webrequest_source</name></property>
        <property><name>record_version</name></property>
        <property><name>data_loss_check_directory_base</name></property>
        <property><name>error_incomplete_data_threshold</name></property>
        <property><name>warning_incomplete_data_threshold</name></property>
        <property><name>error_data_loss_threshold</name></property>
        <property><name>warning_data_loss_threshold</name></property>
        <property><name>mark_directory_done_workflow_file</name></property>
        <property><name>send_error_email_workflow_file</name></property>
        <property><name>sla_alert_contact</name></property>
    </parameters>

    <controls>
        <!--
        If everything goes smoothly, we need a timeout of at least 1
        hour, due to the waiting on a subsequent dataset. Hence, the
        cluster's default timeout of 2 hours (our cluster does not use
        the Oozie default) gets in the way as soon as there are minor
        transient hiccups. Hence, we use a slightly higher timeout on
        purpose. This timeout helps us to bridge smaller transient
        issues automatically.

        (timeout is measured in minutes)
        -->
        <timeout>300</timeout>

        <!--
        Computing sequence stats is not too cheap, so we limit
        concurrency.

        Note, that this is per coordinator. So if we run this
        coordinator for say 4 webrequest_sources (see bundle.xml :-)),
        we effectively compute sequence statistics for up to 8
        datasets in parallel.

        Also note, that back-filling is not limited by the
        coordinator's frequency, so back-filling works nicely
        even-though the concurrency is low.
        -->
        <concurrency>2</concurrency>


        <!--
        Since we expect only one incarnation per hourly dataset, the
        default throttle of 12 is way to high, and there is not need
        to keep that many materialized jobs around.

        By resorting to 2, we keep the hdfs checks on the datasets
        low, while still being able to easily feed the concurrency.
        -->
        <throttle>2</throttle>
    </controls>

    <datasets>
        <!--
        Include the given datasets files.  This should
        define the "webrequest_*_raw" and "webrequest_*" datasets
        -->
        <include>${webrequest_raw_datasets_file}</include>
        <include>${webrequest_datasets_file}</include>
    </datasets>

    <input-events>
        <data-in name="raw_unchecked_input" dataset="webrequest_${webrequest_source}_raw_unchecked">
            <instance>${coord:current(0)}</instance>
        </data-in>
    </input-events>

    <output-events>
        <!--
          Note: This coordinator generates both the webrequest_${webrequest_source}_raw
          (with a hive partition) and the webrequest_${webrequest_source} (refined)
          datasets.
          The webrequest_${webrequest_source}_raw one is not included here to prevent
          accidentally deleting the raw-data folder if rerunning actions without the
          nocleanup oozie flag.
          See https://oozie.apache.org/docs/3.1.3-incubating/DG_CoordinatorRerun.html
        -->
        <data-out name="refined_output" dataset="webrequest_${webrequest_source}">
            <instance>${coord:current(0)}</instance>
        </data-out>
    </output-events>


    <action>
        <workflow>
            <app-path>${workflow_file}</app-path>
            <configuration>
                <!-- we choose not to pad date values because hive behaves
                     better when the partition is not padded as padded string,
                     and we wanted to keep partitions and locations consistent-->
                <property>
                    <name>year</name>
                    <value>${coord:formatTime(coord:nominalTime(), "y")}</value>
                </property>
                <property>
                    <name>month</name>
                    <value>${coord:formatTime(coord:nominalTime(), "M")}</value>
                </property>
                <property>
                    <name>day</name>
                    <value>${coord:formatTime(coord:nominalTime(), "d")}</value>
                </property>
                <property>
                    <name>hour</name>
                    <value>${coord:formatTime(coord:nominalTime(), "H")}</value>
                </property>
                <property>
                    <name>webrequest_raw_location</name>
                    <value>${coord:dataIn('raw_unchecked_input')}</value>
                </property>
                <property>
                    <name>webrequest_location</name>
                    <value>${coord:dataOut('refined_output')}</value>
                </property>
            </configuration>
        </workflow>
        <sla:info>
            <!--
                Use action actual time as SLA base, since it's the time used
                to compute timeout
            -->
            <sla:nominal-time>${coord:actualTime()}</sla:nominal-time>
            <sla:should-end>${5 * HOURS}</sla:should-end>
            <sla:alert-events>end_miss</sla:alert-events>
            <sla:alert-contact>${sla_alert_contact}</sla:alert-contact>
        </sla:info>
    </action>
</coordinator-app>
