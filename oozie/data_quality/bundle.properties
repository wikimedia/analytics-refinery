# Hadoop properties.
name_node                           = hdfs://analytics-hadoop
job_tracker                         = resourcemanager.analytics.eqiad.wmnet:8032
hive2_jdbc_url                      = jdbc:hive2://an-coord1001.eqiad.wmnet:10000/default
queue_name                          = default
user                                = analytics

# HDFS base path to refinery.
# When submitting this job for production, you should override this to point
# directly at a deployed directory, and not the symbolic 'current' directory.
# E.g.:  /wmf/refinery/2015-01-05T17.59.18Z--7bb7f07
refinery_directory                  = ${name_node}/wmf/refinery/current

# HDFS path to artifacts that will be used by this job.
# E.g. refinery-hive.jar should exist here.
artifacts_directory                 = ${refinery_directory}/artifacts

# HDFS base path to oozie files.
# Other files will be referenced relative to this path.
oozie_directory                     = ${refinery_directory}/oozie

# HDFS path to xml files.
bundle_file                         = ${oozie_directory}/data_quality/${granularity}/bundle.xml
coordinator_file                    = ${oozie_directory}/data_quality/${granularity}/coordinator.xml
workflow_file                       = ${oozie_directory}/data_quality/${granularity}/workflow.xml

# Information about the destination data set.
data_quality_table                  = wmf.data_quality_${granularity}
data_quality_directory              = ${name_node}/wmf/data/wmf/data_quality/${granularity}

# Version of the refinery-source jar.
refinery_jar_version                = 0.0.93

# HDFS path to hive-site.xml file.
hive_site_xml                       = ${name_node}/user/hive/hive-site.xml

# Auxiliary workflow files.
send_error_email_workflow_file      = ${oozie_directory}/util/send_error_email/workflow.xml
flag_directory_done_workflow_file   = ${oozie_directory}/util/mark_directory_done/workflow.xml

# Default time to stop running this coordinator. Year 3000 == never!
stop_time                           = 3000-01-01T00:00Z

# Default done flag for input data sets.
done_flag                           = _SUCCESS

# Coordintator to start.
oozie.bundle.application.path       = ${bundle_file}
oozie.use.system.libpath            = true
oozie.action.external.stats.write   = true
