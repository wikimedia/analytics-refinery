<?xml version="1.0" encoding="UTF-8"?>
<!--
FIXME Deprecated by hql/aqs/hourly + Airflow

Defines reusable datasets for aqs data.
Use this dataset in your coordinator.xml files by setting:

    ${start_time}     - the initial instance of your data.
                        Example: 2014-04-01T00:00Z
    ${aqs_data_directory} - Path to directory where aqs data is time bucketed.
                        Example: /wmf/data/wmf/aqs
-->

<datasets>

    <!--
    To unpad MONTH, DAY, and HOUR, we force coercion to a number by
    adding 0.

    Note that we do not use “${...}” but “${"$"}{...}", as dataset files are
    passed to EL twice in cascade, and in the first EL level, ${MONTH}
    evaluates to the string “${MONTH}”. Hence, we escape the dollar sign in
    “${....}" to “${"$"}{...}”. At the first EL level, “${"$"}” gets turned
    into a dollar sign, and “{...}”  is just passed along. Hence, we arrive
    at “${...}” as input for the second EL level. There, the variables hold
    their expected values, and we can start unpadding them.
    -->
    <dataset name="aqs_hourly"
             frequency="${coord:hours(1)}"
             initial-instance="${start_time}"
             timezone="Universal">
        <uri-template>${aqs_data_directory}/hourly/year=${YEAR}/month=${"$"}{MONTH + 0}/day=${"$"}{DAY + 0}/hour=${"$"}{HOUR + 0}</uri-template>
        <done-flag>_SUCCESS</done-flag>
    </dataset>
</datasets>
