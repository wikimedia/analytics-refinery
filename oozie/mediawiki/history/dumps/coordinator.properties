# Default properties to execute the mediawiki history dumps coordinator.
# Read the README.md for a summary of this job and for more information
# on details, caveats and how to run the job in the command line.

# Oozie properties.
name_node                           = hdfs://analytics-hadoop
job_tracker                         = resourcemanager.analytics.eqiad.wmnet:8032
queue_name                          = default
oozie_launcher_queue_name           = ${queue_name}
hive_principal                      = hive/analytics-hive.eqiad.wmnet@WIKIMEDIA
hive_metastore_uri                  = thrift://analytics-hive.eqiad.wmnet:9083
oozie_launcher_memory               = 2048

# HDFS base paths.
refinery_directory                  = ${name_node}/wmf/refinery/current
oozie_directory                     = ${refinery_directory}/oozie
artifacts_directory                 = ${refinery_directory}/artifacts
temporary_directory                 = ${name_node}/wmf/tmp/analytics
mw_directory                        = ${name_node}/wmf/data/wmf/mediawiki
input_base_path                     = ${mw_directory}/history
output_base_path                    = ${name_node}/wmf/data/archive/mediawiki/history

# XML files.
mediawiki_history_datasets_file     = ${oozie_directory}/mediawiki/history/datasets.xml
workflow_file                       = ${oozie_directory}/mediawiki/history/dumps/workflow.xml
send_error_email_workflow_file      = ${oozie_directory}/util/send_error_email/workflow.xml

# Default start/stop times.
start_time                          = 2019-08-01T00:00Z
stop_time                           = 3000-01-01T00:00Z

# Spark properties.
oozie_spark_lib                     = spark-2.4.4
spark_master                        = yarn
spark_deploy_mode                   = cluster
spark_job_name                      = mediawiki-history-dumps
spark_job_class                     = org.wikimedia.analytics.refinery.job.mediawikihistory.MediawikiHistoryDumper
spark_job_jar                       = ${artifacts_directory}/org/wikimedia/analytics/refinery/refinery-job-0.0.134.jar
spark_driver_memory                 = 16G
spark_executor_memory               = 16G
spark_executor_memory_overhead      = 4096
spark_executor_cores                = 2
spark_max_num_executors             = 80
spark_temp_partitions               = 4096

# SLA properties.
sla_alert_contact                   = analytics-alerts@wikimedia.org
# One more day than denormalize
sla_miss_after_days                 = 35

# Coordintator to start.
oozie.coord.application.path        = ${oozie_directory}/mediawiki/history/dumps/coordinator.xml
oozie.use.system.libpath            = true
oozie.action.external.stats.write   = true
