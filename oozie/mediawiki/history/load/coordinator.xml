<?xml version="1.0" encoding="UTF-8"?>
<coordinator-app xmlns="uri:oozie:coordinator:0.4"
    xmlns:sla="uri:oozie:sla:0.2"
    name="mediawiki-history-load-coord"
    frequency="${coord:months(1)}"
    start="${start_time}"
    end="${stop_time}"
    timezone="Universal">

    <parameters>
        <!-- Required properties -->
        <property><name>queue_name</name></property>
        <property><name>name_node</name></property>
        <property><name>job_tracker</name></property>
        <property><name>hive_principal</name></property>
        <property><name>hive2_jdbc_url</name></property>
        <property><name>workflow_file</name></property>
        <property><name>start_time</name></property>
        <property><name>stop_time</name></property>

        <!-- Passing both raw and raw_private datasets and directorie
             to prevent repeating them in bundle coord definitions  -->
        <property><name>datasets_raw_file</name></property>
        <property><name>mw_raw_directory</name></property>
        <property><name>datasets_raw_private_file</name></property>
        <property><name>mw_raw_private_directory</name></property>

        <property><name>mw_table</name></property>
        <property><name>mw_table_dataset</name></property>
        <property><name>previous_dataset</name></property>

        <property><name>hive_site_xml</name></property>
        <property><name>repair_partitions_workflow_file</name></property>
        <property><name>mark_directory_done_workflow_file</name></property>
        <property><name>send_error_email_workflow_file</name></property>

        <property><name>sla_alert_contact</name></property>
    </parameters>

    <controls>
        <!--(timeout is measured in minutes)-->
        <timeout>-1</timeout>

        <!-- Setting low concurrency for resource sharing.
             The job runs pretty fast (~1 minute) and increasing concurrency should not cause any problems-->
        <concurrency>1</concurrency>

        <throttle>2</throttle>

    </controls>

    <datasets>
        <include>${datasets_raw_file}</include>
        <include>${datasets_raw_private_file}</include>
    </datasets>

    <input-events>
        <data-in name="mw_table_dataset" dataset="${mw_table_dataset}">
            <instance>${coord:current(0)}</instance>
        </data-in>

        <!--
          The following dependency makes the coordinator wait for a previous dataset
          to be available before starting. This allows us to force mediawiki-load
          coordinators to run one after the other, preventing multiple big repairs to
          overload the Hive metastore. This however couples datasets, as a a following
          dataset is dependent on the previous ones to be successfully loaded.
          This hack should be removed if the metastore can handle the multiple repairs,
          so that the datasets are not coupled anymore
        -->
        <data-in name="previous_dataset" dataset="${previous_dataset}">
            <instance>${coord:current(0)}</instance>
        </data-in>
    </input-events>

    <output-events>
        <!-- Datasets for hive partitions synchronisation-->
        <data-out name="mw_table_dataset_partitioned" dataset="${mw_table_dataset}_partitioned">
            <instance>${coord:current(0)}</instance>
        </data-out>
    </output-events>

    <action>
        <workflow>
            <app-path>${workflow_file}</app-path>
            <configuration>
                <property>
                    <name>snapshot</name>
                    <value>${coord:formatTime(coord:nominalTime(), "yyyy")}-${coord:formatTime(coord:nominalTime(), "MM")}</value>
                </property>
                <property>
                    <name>mw_data_location</name>
                    <value>${coord:dataIn('mw_table_dataset')}</value>
                </property>
            </configuration>
        </workflow>

        <sla:info>
            <!--
                Use action actual time as SLA base, since it's the time used
                to compute timeout
                Job is waiting for the month data to be present, then sqoop
                does its job, so waiting for 3 days after month end should
                be enough.
            -->
            <sla:nominal-time>${coord:actualTime()}</sla:nominal-time>
            <sla:should-end>${34 * DAYS}</sla:should-end>
            <sla:alert-events>end_miss</sla:alert-events>
            <sla:alert-contact>${sla_alert_contact}</sla:alert-contact>
        </sla:info>

    </action>
</coordinator-app>
