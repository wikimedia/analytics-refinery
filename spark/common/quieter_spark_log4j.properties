# SPDX-License-Identifier: Apache-2.0

# This adhoc properties file for log4j should be used in the context of a Spark
# application where you want to reduce the quantity of Spark logs usually
# to focus on the application logs.

# Set everything to be logged to the console
log4j.rootCategory=INFO, console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

# spark REPL
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO

# Parquet
log4j.logger.org.apache.parquet=ERROR
log4j.logger.parquet=ERROR

# Hive
hive.log.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n
hive.log.console.layout=org.apache.log4j.PatternLayout
hive.log.console=org.apache.log4j.ConsoleAppender
hive.root.logger=WARN, console
log4j.logger.Hive=WARN
log4j.logger.hive.*=WARN
log4j.logger.hive.metastore=WARN
log4j.logger.hive.ql.metadata.Hive=WARN
log4j.logger.org.apache.hadoop.hive.*=WARN
# SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support
log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL
log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR

# Spark internals
log4j.logger.org.apache.spark.*=WARN

# Spark SQL
log4j.logger.org.apache.spark.sql=WARN
log4j.logger.org.apache.spark.sql.*=WARN

# Jetty
log4j.logger.org.sparkproject.jetty.server.AbstractConnector=WARN
log4j.logger.org.sparkproject.jetty.server.Server=WARN
log4j.logger.org.sparkproject.jetty.server.handler.ContextHandler=WARN
log4j.logger.org.sparkproject.jetty.servlet.ServletContextHandler=WARN
log4j.logger.org.sparkproject.jetty.util.log.Slf4jLog=WARN
log4j.logger.org.sparkproject.jetty=WARN

# Hadoop
log4j.logger.org.apache.hadoop.*=WARN

# Log4j
log4j.logger.log=WARN
log4j.logger.org.apache=WARN

