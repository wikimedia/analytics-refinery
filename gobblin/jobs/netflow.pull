include=/srv/deployment/analytics/refinery/gobblin/common/kafka_to_hdfs_hourly.properties

job.name=netflow
job.group=gobblin
extract.namespace=org.wikimedia.analytics.netflow

topic.include=netflow

writer.partition.timestamp.columns=stamp_inserted
writer.partition.timestamp.format=yyyy-MM-dd' 'HH:mm:ss

mr.job.max.mappers=4
mapreduce.job.queuename=essential

bootstrap.with.offset=latest

# To be changed to /wmf/data/raw/netflow when finalizing
# the move from camus to gobblin
data.publisher.final.dir=/wmf/data/raw/netflow
