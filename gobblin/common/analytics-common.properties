#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#


# Common Gobblin WMF Analytics MapReduce configurations.
#
# These settings are common to all gobblin jobs used for
# ingesting into Analytics Hadoop clusters.
#
# This file is meant to be included from a Gobblin sysconfig.properties fille.
# fs.uri and related settings are not set here; they should be set in
# a specific sysconfig.properties file to identify the Hadoop cluster
# into which the job will import.


gobblin.cluster.work.dir=/wmf/gobblin

# Thread pool settings for the task executor
taskexecutor.threadpool.size=2
taskretry.threadpool.coresize=1
taskretry.threadpool.maxsize=2

# Writer related configuration properties
writer.destination.type=HDFS
writer.output.format=TXT
writer.file.permissions=640
writer.dir.permissions=750

# Data publisher related configuration properties
data.publisher.type=org.apache.gobblin.publisher.BaseDataPublisher
data.publisher.replace.final.dir=false
# Only for directories created by the publisher. Directories and files
# created by the writer have their permissions set by the writer.
data.publisher.permissions=750

# Directory where job/task state files are stored
state.store.dir=${gobblin.cluster.work.dir}/state_store

# Directory where error files from the quality checkers are stored
qualitychecker.row.err.file=${gobblin.cluster.work.dir}/err

# Disable lock to prevent job being stuck without us noticing
# This should be removed once we have metrics and alerts
job.lock.enabled = false
# Directory where job locks are stored - nulled while lock is disabled
# job.lock.dir=${gobblin.cluster.work.dir}/locks

# Directory where metrics log files are stored
metrics.log.dir=${gobblin.cluster.work.dir}/metrics
metrics.reporting.file.suffix=txt

# Interval of task state reporting in milliseconds
task.status.reportintervalinms=5000

# MapReduce properties
mr.job.root.dir=${gobblin.cluster.work.dir}/mr_working
mapreduce.job.queuename=essential

task.data.root.dir=${gobblin.cluster.work.dir}/task_working
